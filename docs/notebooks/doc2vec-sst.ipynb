{
 "metadata": {
  "name": "",
  "signature": "sha256:74d8aa75be0ba87e9c2332fef9eeedefa5c162f00741674e2878f0e091ec3bae"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "gensim doc2vec & Stanford Sentiment Treebank"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# while developing, auto-reload changed source\n",
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load corpus"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data available from http://nlp.Stanford.edu/sentiment/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim.corpora import susentcorpus\n",
      "corpus = susentcorpus.StanfordSentimentCorpus('stanfordSentimentTreebank')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Set-up Training & Evaluation Models"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Approximating experiment of Le & Mikolov [\"Distributed Representations of Sentences and Documents\"](http://cs.stanford.edu/~quocle/paragraph_vector.pdf), 400 dimensions of each model, \"PV-DM\" and \"PV-DBOW\". "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim.models import Doc2Vec\n",
      "dbow_model = Doc2Vec(dm=0,size=400,hs=0,negative=15,min_count=1,workers=4,seed=1)\n",
      "dm_model = Doc2Vec(dm=1,dm_mean=1,size=400,hs=0,negative=15,min_count=1,window=7,workers=4,seed=2) # dm_mean=1 gives more sensible word similarities, faster improvement per pass on sentiment predictions\n",
      "# dm_concat model with giant layer1 uses most RAM: ~5GB\n",
      "# dm_concat model not yet cythonized/BLAS-enabled: takes 60x longer per training pass\n",
      "dmc_model = Doc2Vec(dm=1,dm_concat=1,size=400,hs=0,negative=15,min_count=1,window=7,workers=4,seed=3)\n",
      "\n",
      "# note: using different seeds seems to help prevent \"LinAlgError: Singular Matrix\" during *some* \n",
      "# regressions on concatenated-models, perhaps due to certain doc vectors repeating exactly? "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# if more visual progress wanted in vocab/training steps, uncomment\n",
      "#import logging\n",
      "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
      "#rootLogger = logging.getLogger()\n",
      "#rootLogger.setLevel(logging.INFO)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Prep vocabulary. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dmc_model.build_vocab(corpus)  # includes null_word (others don't)\n",
      "#dbow_model.build_vocab(corpus)\n",
      "#dm_model.build_vocab(corpus)\n",
      "# avoid duplication of work/memory: copy vocab results to other models\n",
      "dm_model.vocab, dm_model.index2word, dm_model.table = dmc_model.vocab, dmc_model.index2word, dmc_model.table\n",
      "dm_model.reset_weights()\n",
      "dbow_model.vocab, dbow_model.index2word, dbow_model.table = dmc_model.vocab, dmc_model.index2word, dmc_model.table\n",
      "dbow_model.reset_weights()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Evaluate a model's bulk-trained or inferred doc vectors for coarse-sentiment prediction value. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from numpy import concatenate\n",
      "import statsmodels.api as sm\n",
      "\n",
      "def error_rate_for_model(model_list, corpus, infer=False, steps=50):\n",
      "    \"\"\"Report error rate on SU Sentiment Treebank TEST sentences for given models/model-concatenations.\"\"\"\n",
      "    # train data: just the full TRAIN sentences\n",
      "    train_sentences = [sentence for sentence in corpus.split(corpus.TRAIN) if 'PHR_%i'%sentence.id in model_list[0].vocab]\n",
      "    train_coarse_sentiments = np.array([round(sentence.sentiment,0) for sentence in train_sentences])\n",
      "    \n",
      "    # bulk-learned doc vectors for TRAIN sentences\n",
      "    train_regressors = concatenate([[model['PHR_%i'%sentence.id] for sentence in train_sentences] for model in model_list], axis=1)\n",
      "    train_regressors = sm.add_constant(train_regressors)\n",
      "\n",
      "    # logistic regression\n",
      "    logit = sm.Logit(train_coarse_sentiments, train_regressors)\n",
      "    logit_result = logit.fit(disp=0)\n",
      "    #print(logit_result.summary())\n",
      "    \n",
      "    # test data & vectors \n",
      "    if infer:\n",
      "        test_sentences = corpus.split(corpus.TEST)  # use all: no dependence on prior training\n",
      "        test_regressors = concatenate([[model.infer_vector(sentence.text.split(),steps) for sentence in test_sentences] for model in model_list], axis=1)\n",
      "    else:\n",
      "        # use vectors left-over from bulk training\n",
      "        test_sentences = [sentence for sentence in corpus.split(corpus.TEST) if 'PHR_%i'%sentence.id in model_list[0].vocab]\n",
      "        test_regressors = concatenate([[model['PHR_%i'%sentence.id] for sentence in test_sentences] for model in model_list], axis=1)\n",
      "    test_regressors = sm.add_constant(test_regressors)\n",
      "    test_coarse_sentiments = [round(sentence.sentiment,0) for sentence in test_sentences]\n",
      "\n",
      "    # predict & evaluate\n",
      "    test_predictions = logit_result.predict(test_regressors)\n",
      "    error_rate = sum([1 for pair in zip(test_coarse_sentiments,[round(predict,0) for predict in test_predictions]) if pair[0] != pair[1]]) / len(test_predictions)\n",
      "    return error_rate\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Bulk Training"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use manual multiple-pass, alpha-reduction approach as sketched in [gensim doc2vec blog post](http://radimrehurek.com/2014/12/doc2vec-tutorial/) \u2013 with added shuffling of corpus on each pass.\n",
      "\n",
      "Note that training is occurring on *all* phrases of the dataset, which includes all TRAIN/TEST/DEV sentences and their subphrases. (The subphrases aren't marked as TRAIN/TEST/DEV or with their source sentence - for now skipping the (239K phrases * 12K sentences) substring search that'd be required to split.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from random import shuffle\n",
      "from collections import OrderedDict, defaultdict\n",
      "\n",
      "alpha = 0.025 # 0.025\n",
      "passes = 200\n",
      "alpha_delta = (alpha - 0.0001) / passes\n",
      "models_by_name = OrderedDict([\n",
      "    ('dbow', [dbow_model]),\n",
      "    ('dm', [dm_model]),\n",
      "    ('dm+dbow', [dm_model, dbow_model]),\n",
      "    ('dmc', [dmc_model]),\n",
      "    ('dmc+dbow', [dmc_model, dbow_model]),\n",
      "])\n",
      "best_error = defaultdict(lambda :1.0)\n",
      "infer_per = 10  # inference quite slow: only do every 10th pass\n",
      "infer_steps = 100\n",
      "\n",
      "for epoch in range(passes):\n",
      "    shuffled = list(corpus)\n",
      "    shuffle(shuffled)\n",
      "    \n",
      "    for name, model in models_by_name.items():\n",
      "        \n",
      "        if len(model) == 1:\n",
      "            # only train the pure models\n",
      "            model[0].alpha = alpha\n",
      "            model[0].min_alpha = alpha\n",
      "            model[0].train(shuffled)\n",
      "        err = error_rate_for_model(model,corpus)\n",
      "        if err < best_error[name]:\n",
      "            best_error[name] = err\n",
      "            print(\"%f : %i passes : %s\"%(err,epoch+1,name))\n",
      "        if (epoch+1) % infer_per == 0:\n",
      "            infer_err = error_rate_for_model(model,corpus,infer=True,steps=infer_steps)\n",
      "            if infer_err < best_error[name+'_inferred']:\n",
      "                best_error[name+'_inferred'] = infer_err\n",
      "                print(\"%f : %i passes : %s\"%(infer_err,epoch+1,name+'_inferred'))\n",
      "\n",
      "    print('completed pass %i at alpha %f'%(epoch+1,alpha))\n",
      "    alpha -= alpha_delta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.483710 : 1 passes : dbow\n",
        "0.489140 : 1 passes : dm"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.463348 : 1 passes : dm+dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.508597 : 1 passes : dmc"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.493665 : 1 passes : dmc+dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 1 at alpha 0.025000\n",
        "0.459729 : 2 passes : dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.423529 : 2 passes : dm"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.437557 : 2 passes : dm+dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.479638 : 2 passes : dmc+dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 2 at alpha 0.024876\n",
        "0.431222 : 3 passes : dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.390950 : 3 passes : dm"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.395928 : 3 passes : dm+dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.451584 : 3 passes : dmc+dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 3 at alpha 0.024751\n",
        "0.406787 : 4 passes : dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.378281 : 4 passes : dm"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.363348 : 4 passes : dm+dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.426244 : 4 passes : dmc+dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 4 at alpha 0.024627\n",
        "0.399095 : 5 passes : dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.351131 : 5 passes : dm"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.355204 : 5 passes : dm+dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.414932 : 5 passes : dmc+dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 5 at alpha 0.024502\n",
        "0.368326 : 6 passes : dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.348869 : 6 passes : dm"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.327602 : 6 passes : dm+dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.502262 : 6 passes : dmc"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.387330 : 6 passes : dmc+dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 6 at alpha 0.024378\n",
        "0.361991 : 7 passes : dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.337557 : 7 passes : dm"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.498190 : 7 passes : dmc"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.370136 : 7 passes : dmc+dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 7 at alpha 0.024253\n",
        "0.340724 : 8 passes : dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.328959 : 8 passes : dm"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.319005 : 8 passes : dm+dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.494118 : 8 passes : dmc"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.353846 : 8 passes : dmc+dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 8 at alpha 0.024129\n",
        "0.333032 : 9 passes : dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.328507 : 9 passes : dm"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.314932 : 9 passes : dm+dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.489140 : 9 passes : dmc"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 9 at alpha 0.024004"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.320814 : 10 passes : dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.410407 : 10 passes : dbow_inferred"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.318552 : 10 passes : dm"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.372851 : 10 passes : dm_inferred"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.312217 : 10 passes : dm+dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.399548 : 10 passes : dm+dbow_inferred"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.488688 : 10 passes : dmc"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.474661 : 10 passes : dmc_inferred"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.337104 : 10 passes : dmc+dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.412217 : 10 passes : dmc+dbow_inferred"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 10 at alpha 0.023880\n",
        "0.308145 : 11 passes : dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.308145 : 11 passes : dm+dbow"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-8-f6011a51e153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_rate_for_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_error\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/scratch/Documents/dev2015/gensim_venv/src/gensim-develop/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, total_words, word_count, chunksize)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mjob_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"putting job #%i in the queue, qsize=%i\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjob_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reached the end of input; waiting to finish %i outstanding jobs\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/scratch/miniconda3/envs/gensim_cenv/lib/python3.4/queue.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(self, item, block, timeout)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/scratch/miniconda3/envs/gensim_cenv/lib/python3.4/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After hundreds of passes, I've seen the DBOW model reach an error of about 27% and the DM model reach around 30%. The DM_CONCAT model is still 40%+ after a dozen or more passes (which is usually enough to get the other models into the low 30s). These are still very far from the paper's reported 12.2% error rate. Theories include:\n",
      "\n",
      "* the much larger PV-DM/concatenation model may need many, many more training passes to get good results? if so, impractical until cythonized/BLASized \n",
      "* paper *maybe* used pretrained word vectors from a much larger corpus?\n",
      "* other differences in training parameter choices/passes/corpus-cleanup?\n",
      "* an implementation flaw? the new DM_CONCAT code is nowhere near the paper's claim that \"PV-DM alone usually works well for most tasks (with state-of-art performances)\". But also, \"combination with PV-DBOW\" (as the paper recommends) is far from helping much, either, on these trials. Still the doc vectors have *some* predictive power, improving over time, and show many of the patterns in word and doc similarity relationships that would be expected from meaningful training."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Miscellaneous"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# do the nearby words make sense?\n",
      "from IPython.display import HTML\n",
      "word = 'actor'\n",
      "similars_per_model = [str(model.most_similar(word)).replace('), ','),<br>\\n') for model in [dbow_model, dm_model, dmc_model]]\n",
      "similar_table = (\"<table><tr><th>DBOW</th><th>DM</th><th>DMC</th></tr><tr><td>\" + \n",
      "    \"</td><td>\".join(similars_per_model) +\n",
      "    \"</td></tr></table>\")\n",
      "print(\"most similar words for %s\"%word)\n",
      "HTML(similar_table)\n",
      "# IMO all kind of weak compared to larger datasets; DMC looked best after ~13 equal passes "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "most similar words for actor\n"
       ]
      },
      {
       "html": [
        "<table><tr><th>DBOW</th><th>DM</th><th>DMC</th></tr><tr><td>[('Cross', 0.23156070709228516),<br>\n",
        "('Watson', 0.20430749654769897),<br>\n",
        "('fantastically', 0.18972325325012207),<br>\n",
        "('ounce', 0.18611034750938416),<br>\n",
        "('backlash', 0.18284499645233154),<br>\n",
        "('evangelical', 0.17659470438957214),<br>\n",
        "('Hayek', 0.17577606439590454),<br>\n",
        "('who-wrote-Shakespeare', 0.17459481954574585),<br>\n",
        "('vertiginous', 0.17310573160648346),<br>\n",
        "('topnotch', 0.17294824123382568)]</td><td>[('performance', 0.5356020927429199),<br>\n",
        "('role', 0.5084348917007446),<br>\n",
        "('actress', 0.5067117214202881),<br>\n",
        "('artist', 0.4479498565196991),<br>\n",
        "('storyteller', 0.4363330900669098),<br>\n",
        "('encounter', 0.42748719453811646),<br>\n",
        "('portrayal', 0.4228925108909607),<br>\n",
        "('PHR_67170', 0.4050571322441101),<br>\n",
        "('PHR_195510', 0.3967461585998535),<br>\n",
        "('Martin', 0.3961438536643982)]</td><td>[('horton', 0.5451996326446533),<br>\n",
        "('act', 0.5179077386856079),<br>\n",
        "('name', 0.5032098293304443),<br>\n",
        "('debuter', 0.4832889139652252),<br>\n",
        "('epic', 0.476888507604599),<br>\n",
        "('filmmaker', 0.4763982892036438),<br>\n",
        "('hooters', 0.4740758538246155),<br>\n",
        "('actress', 0.4730053246021271),<br>\n",
        "('winner', 0.4726346433162689),<br>\n",
        "('Greene', 0.47250914573669434)]</td></tr></table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "<IPython.core.display.HTML at 0x28ac2bf98>"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# what are nearby bulk-trained vectors for an inferred vector?\n",
      "phrase = corpus.split(corpus.TEST)[0]\n",
      "tokens = phrase.text.split(' ')\n",
      "similars_per_model = [str(model.most_similar([model.infer_vector(tokens,steps=1000,alpha=0.1)])).replace('), ','),<br>\\n') for model in [dbow_model, dm_model, dmc_model]]\n",
      "print(\"most similar docs for %i: '%s'\" %(phrase.id, phrase.text))\n",
      "similar_table = (\"<table><tr><th>DBOW</th><th>DM</th><th>DMC</th></tr><tr><td>\" + \n",
      "    \"</td><td>\".join(similars_per_model) +\n",
      "    \"</td></tr></table>\")\n",
      "HTML(similar_table)\n",
      "# in DBOW, often phrase itself or subphrase... less consistent DM/DM_CONCAT"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "most similar docs for 9542: 'ordinary melodrama that is heavy on religious symbols but wafer-thin on dramatic substance'\n"
       ]
      },
      {
       "html": [
        "<table><tr><th>DBOW</th><th>DM</th><th>DMC</th></tr><tr><td>[('PHR_9542', 0.9218934774398804),<br>\n",
        "('PHR_168364', 0.9000791907310486),<br>\n",
        "('PHR_11079', 0.8982703685760498),<br>\n",
        "('PHR_7720', 0.8948874473571777),<br>\n",
        "('PHR_173047', 0.8919961452484131),<br>\n",
        "('PHR_7080', 0.8743342757225037),<br>\n",
        "('PHR_7719', 0.8735879063606262),<br>\n",
        "('PHR_120271', 0.8640589714050293),<br>\n",
        "('PHR_29857', 0.862522304058075),<br>\n",
        "('PHR_39845', 0.8591123819351196)]</td><td>[('PHR_168364', 0.599272608757019),<br>\n",
        "('PHR_9542', 0.598691463470459),<br>\n",
        "('PHR_172975', 0.5743072032928467),<br>\n",
        "('PHR_236390', 0.5664645433425903),<br>\n",
        "('PHR_11079', 0.5618088245391846),<br>\n",
        "('PHR_22202', 0.5566954016685486),<br>\n",
        "('PHR_173022', 0.5541336536407471),<br>\n",
        "('PHR_24388', 0.5521167516708374),<br>\n",
        "('PHR_3985', 0.5477848649024963),<br>\n",
        "('PHR_11144', 0.5436711311340332)]</td><td>[('PHR_26767', 0.9981411099433899),<br>\n",
        "('PHR_149261', 0.9980892539024353),<br>\n",
        "('PHR_83460', 0.9980486631393433),<br>\n",
        "('PHR_193952', 0.9979734420776367),<br>\n",
        "('PHR_31335', 0.9979475736618042),<br>\n",
        "('PHR_149674', 0.9978951215744019),<br>\n",
        "('PHR_121949', 0.9978364109992981),<br>\n",
        "('PHR_5937', 0.9977949857711792),<br>\n",
        "('PHR_69527', 0.997748851776123),<br>\n",
        "('PHR_79498', 0.9977131485939026)]</td></tr></table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "<IPython.core.display.HTML at 0x28a5681d0>"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# viewing a phrase by id\n",
      "' '.join(corpus[168364].words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "'ordinary melodrama that is heavy on religious symbols but wafer-thin'"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}