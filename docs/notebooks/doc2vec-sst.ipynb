{
 "metadata": {
  "name": "",
  "signature": "sha256:3430bdbfbaefcd30ad71b25403f9f4d835edfab32bd183350405e8699c865efe"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "gensim doc2vec & Stanford Sentiment Treebank"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# while developing, auto-reload changed source\n",
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load corpus"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data available from http://nlp.Stanford.edu/sentiment/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim.corpora import susentcorpus\n",
      "corpus = susentcorpus.StanfordSentimentCorpus('stanfordSentimentTreebank')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Bulk-train doc vectors"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Approximating experiment of Le & Mikolov [\"Distributed Representations of Sentences and Documents\"](http://cs.stanford.edu/~quocle/paragraph_vector.pdf), 300 dimensions of each model, \"PV-DM\" and \"PV-DBOW\". "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim.models import Doc2Vec\n",
      "dm_model = Doc2Vec(dm=1,size=300,min_count=3,workers=2)\n",
      "dbow_model = Doc2Vec(dm=0,size=300,min_count=3,workers=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# if more visual progress wanted in vocab/training steps, uncomment\n",
      "#import logging\n",
      "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
      "#rootLogger = logging.getLogger()\n",
      "#rootLogger.setLevel(logging.INFO)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(Possible optimization: copy vocab structure between models; they are same for this step.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dm_model.build_vocab(corpus)\n",
      "dbow_model.build_vocab(corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Usue manual multiple-pass, alpha-reduction approach as sketched in [gensim doc2vec blog post](http://radimrehurek.com/2014/12/doc2vec-tutorial/) \u2013 with added shuffling of corpus on each pass.\n",
      "\n",
      "Note that training is occurring on *all* phrases of the dataset, which includes all TRAIN/TEST/DEV sentences and their subphrases. (The subphrases aren't marked as TRAIN/TEST/DEV or with their source sentence - for now skipping the (239K phrases * 12K sentences) substring search that'd be required to split.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dm_model.reset_weights()\n",
      "dbow_model.reset_weights()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from random import shuffle\n",
      "\n",
      "alpha = 0.0251\n",
      "for epoch in range(25):\n",
      "    shuffled = list(corpus)\n",
      "    shuffle(shuffled)\n",
      "    dm_model.alpha = alpha\n",
      "    dm_model.min_alpha = alpha\n",
      "    dm_model.train(shuffled)\n",
      "    dbow_model.alpha = alpha\n",
      "    dbow_model.min_alpha = alpha\n",
      "    dbow_model.train(shuffled)\n",
      "    print('completed epoch %i at alpha %f'%(epoch,alpha))\n",
      "    alpha -= 0.001"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "completed epoch 0 at alpha 0.025100\n",
        "completed epoch 1 at alpha 0.024100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed epoch 2 at alpha 0.023100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed epoch 3 at alpha 0.022100"
       ]
      }
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Create logistic-regression coarse sentiment predictor"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from numpy import concatenate\n",
      "import statsmodels.api as sm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# take just the full sentences of the corpus in the TRAIN set, if vectors calculated for them\n",
      "train_phrases = [phrase for phrase in corpus.split(corpus.TRAIN) if 'PHR_%i'%phrase.id in dm_model.vocab]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# full sentiments\n",
      "train_sentiments = [phrase.sentiment for phrase in train_phrases]\n",
      "# coarse sentiments (0.0 negative, 1.0 positive)\n",
      "train_coarse = [round(sentiment,0) for sentiment in train_sentiments]\n",
      "\n",
      "# all train-set PV-DM doc vectors\n",
      "dm_train_vectors = [dm_model['PHR_%i'%phrase.id] for phrase in train_phrases]\n",
      "# all train-set PV-DBOW doc vectors\n",
      "dbow_train_vectors = [dbow_model['PHR_%i'%phrase.id] for phrase in train_phrases]\n",
      "\n",
      "# concatenate to 600-dimensional vector per document\n",
      "train_regressors = concatenate((dm_train_vectors,dbow_train_vectors), axis=1)\n",
      "# add constant term needed for regression\n",
      "train_regressors = sm.add_constant(train_regressors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run the logistic regression."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit = sm.Logit(train_coarse,train_regressors)\n",
      "logit_result = logit.fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print(logit_result.summary())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Calculate Prediction Accuracy"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_phrases = [phrase for phrase in corpus.split(corpus.TEST) if 'PHR_%i'%phrase.id in dm_model.vocab]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_coarse = np.array([round(p.sentiment,0) for p in test_phrases])\n",
      "# first try doc-vectors previously trained in bulk (since TEST phrases were included)\n",
      "test_regressors = concatenate([ [dm_model['PHR_%i'%phrase.id] for phrase in test_phrases],[dbow_model['PHR_%i'%phrase.id] for phrase in test_phrases] ], axis=1)\n",
      "test_regressors = sm.add_constant(test_regressors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_predictions = logit_result.predict(test_regressors)\n",
      "logit_error_rate_pretrained = sum([1 for pair in zip(test_coarse,[round(predict,0) for predict in test_predictions]) if pair[0] != pair[1]]) / len(test_predictions)\n",
      "print(\"LOGIT ERROR RATE (Positive/Negative, bulk-trained doc vectors)\\n%f\"%logit_error_rate_pretrained)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is still far from the paper's reported 0.122 error rate. Possible reasons include:\n",
      "* paper used PV-DM with concatenated (not summed/averaged) vectors \u2013 not yet supported by gensim Doc2Vec\n",
      "* paper *maybe* used pretrained word vectors from larger corpus?\n",
      "* other differences in training particulars/passes/corpora-cleanup?\n",
      "\n",
      "Will individually-inferred vectors be much different?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim.models.doc2vec import infer_vector_dm, infer_vector_dbow\n",
      "%time inferred_test_dm = [infer_vector_dm(dm_model,phrase.text.split(),steps=100) for phrase in test_phrases]\n",
      "%time inferred_test_dbow = [infer_vector_dbow(dbow_model,phrase.text.split(),steps=100) for phrase in test_phrases]\n",
      "inferred_test_regressors = concatenate([inferred_test_dm, inferred_test_dbow], axis=1)\n",
      "inferred_test_regressors = sm.add_constant(inferred_test_regressors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# as would be expected, the nearest bulk-trained vector to an inferred vector is for the very same phrase\n",
      "print(str(dm_model.most_similar([inferred_test_dm[0]])[0]))\n",
      "print(str(test_phrases[0].id))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inferred_test_predictions = logit_result.predict(inferred_test_regressors)\n",
      "logit_error_rate_inferred = sum([1 for pair in zip(test_coarse,[round(predict,0) for predict in inferred_test_predictions]) if pair[0] != pair[1]]) / len(test_predictions)\n",
      "print(\"LOGIT ERROR RATE (Positive/Negative, individually-inferred doc vectors)\\n%f\"%logit_error_rate_inferred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Alternate (OLS) regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Might using the coarse targets have thrown-away useful strength-of-sentiment information? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ols = sm.OLS(train_sentiments,train_regressors)\n",
      "ols_result = ols.fit()\n",
      "#print(ols_result.summary())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#test_sentiments = [phrase.sentiment for phrase in test_phrases]\n",
      "test_ols_predictions = ols_result.predict(test_regressors)\n",
      "ols_coarse_error_rate_pretrained = sum([1 for pair in zip(test_coarse,[round(predict,0) for predict in test_ols_predictions]) if pair[0] != pair[1]]) / len(test_ols_predictions)\n",
      "print(\"OLS ERROR RATE (Positive/Negative, bulk-trained doc vectors)\\n%f\"%ols_coarse_error_rate_pretrained)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#test_sentiments = [phrase.sentiment for phrase in test_phrases]\n",
      "test_ols_predictions = ols_result.predict(inferred_test_regressors)\n",
      "ols_coarse_error_rate_inferred = sum([1 for pair in zip(test_coarse,[round(predict,0) for predict in test_ols_predictions]) if pair[0] != pair[1]]) / len(test_ols_predictions)\n",
      "print(\"OLS ERROR RATE (Positive/Negative, individually-inferred doc vectors)\\n%f\"%ols_coarse_error_rate_inferred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(No big difference from coarse/logistical accuracy.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}