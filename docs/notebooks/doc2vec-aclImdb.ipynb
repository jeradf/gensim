{
 "metadata": {
  "name": "",
  "signature": "sha256:a64d46fa4882f7970d31e9eebbffade3bf8dfc460cb8dc4ca78ed7a34d4a5da4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "gensim doc2vec & IMDB sentiment dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# while developing, auto-reload changed source\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "\n",
      "# for timing\n",
      "from contextlib import contextmanager\n",
      "from timeit import default_timer\n",
      "import time \n",
      "\n",
      "@contextmanager\n",
      "def elapsed_timer():\n",
      "    start = default_timer()\n",
      "    elapser = lambda: default_timer() - start\n",
      "    yield lambda: elapser()\n",
      "    end = default_timer()\n",
      "    elapser = lambda: end-start"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load corpus"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "IMDB alldata-id.txt prepped by beginning part of Mikolov's go.sh shell script\n",
      "\n",
      "TODO: maybe make a gensim corpus class with pythonized cleanup, utility methods? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim.models.doc2vec import LabeledSentence\n",
      "alldocs = []\n",
      "with open('/Users/scratch/Documents/dev2015/sent2vec/alldata-id.txt') as alldata:\n",
      "    for line in alldata:\n",
      "        tokens = line.split()\n",
      "        alldocs.append(LabeledSentence(tokens[1:],[tokens[0]]))\n",
      "doc_list = alldocs[:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Set-up Training & Evaluation Models"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Approximating experiment of Mikolov's go.sh:\n",
      "\n",
      "`./word2vec -train ../alldata-id.txt -output vectors.txt -cbow 0 -size 100 -window 10 -negative 5 -hs 0 -sample 1e-4 -threads 40 -binary 0 -iter 20 -min-count 1 -sentence-vectors 1`\n",
      "\n",
      "cbow=0 means skip-gram which is equivalent to 'pv-dbow'"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim.models import Doc2Vec\n",
      "from collections import OrderedDict\n",
      "\n",
      "models_by_name = OrderedDict([\n",
      "   ('dmc_8n5', [Doc2Vec(dm=1,dm_concat=1,size=8,window=5,negative=15,hs=0,min_count=1,workers=4,seed=1)]),\n",
      "#   ('dmc_100hs', [Doc2Vec(dm=1,dm_concat=1,size=100,window=5,negative=0,hs=1,min_count=1,workers=4,seed=1)]),\n",
      "   ('dm_8n5', [Doc2Vec(dm=1,size=8,window=10,negative=5,hs=0,min_count=1,workers=4,seed=1)]),\n",
      "#   ('dm_100hs', [Doc2Vec(dm=1,size=100,window=10,negative=0,hs=1,min_count=1,workers=4,seed=1)]),\n",
      "   ('dbow_8n5', [Doc2Vec(dm=0,size=8,window=10,negative=5,hs=0,min_count=1,workers=4,seed=1,dbow_words=False)]),\n",
      "#   ('dbow_100hs', [Doc2Vec(dm=0,size=100,window=10,negative=0,hs=1,min_count=1,workers=4,seed=1,dbow_words=False)]),\n",
      "])\n",
      "for model_list in models_by_name.values():\n",
      "    [model.build_vocab(alldocs) for model in model_list]\n",
      "\n",
      "#models_by_name['dm+dbow'] = models_by_name['dbow_100'] + models_by_name['dm_100']  # composite; evaluated as concatenated\n",
      "#models_by_name['dmc+dbow'] = models_by_name['dbow_100'] + models_by_name['dmc_100']  # composite; evaluated as concatenated\n",
      "\n",
      "#dbow_300 = Doc2Vec(dm=0,size=300,window=10,negative=5,hs=0,sample=1e-4,min_count=1,workers=4,seed=1)\n",
      "#dbow_preload = Doc2Vec(dm=0,size=300,window=10,negative=5,hs=0,sample=1e-4,min_count=1,workers=4,seed=1)\n",
      "\n",
      "#dm_100 = Doc2Vec(dm=1,size=100,window=10,negative=5,hs=0,sample=1e-4,min_count=1,workers=4,seed=1)\n",
      "#dm_100mean = Doc2Vec(dm=1,dm_mean=1,size=100,window=10,negative=5,hs=0,sample=1e-4,min_count=1,workers=4,seed=1)\n",
      "\n",
      "#dm_300 = Doc2Vec(dm=1,size=300,window=10,negative=5,hs=0,sample=1e-4,min_count=1,workers=4,seed=1)\n",
      "#dm_preload = Doc2Vec(dm=1,size=300,window=10,negative=5,hs=0,sample=1e-4,min_count=1,workers=4,seed=1)\n",
      "#dm_punlock = Doc2Vec(dm=1,size=300,window=10,negative=5,hs=0,sample=1e-4,min_count=1,workers=4,seed=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# maybe, preload vectors?\n",
      "\n",
      "#dm_preload.merge_word2vec_format('/Users/scratch/Documents/dev2015/GoogleNews-vectors-negative300.bin.gz',binary=True)\n",
      "#dbow_preload.merge_word2vec_format('/Users/scratch/Documents/dev2015/GoogleNews-vectors-negative300.bin.gz',binary=True)\n",
      "#import numpy as np\n",
      "#np.copyto(dm_punlock.syn0,dm_preload.syn0)\n",
      "#dm_punlock.syn0locks.fill(1.0) # unlock all terms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Helper methods for evaluating error rate."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from numpy import concatenate\n",
      "import statsmodels.api as sm\n",
      "import random\n",
      "\n",
      "def logistic_predictor_from_data(train_data):\n",
      "    train_targets, train_regressors = zip(*train_data)\n",
      "    train_regressors = sm.add_constant(train_regressors)\n",
      "    logit = sm.Logit(train_targets, train_regressors)\n",
      "    predictor = logit.fit(disp=0)\n",
      "    #print(logit_result.summary())\n",
      "    return predictor\n",
      "\n",
      "def errors_from_model(model_list, predictor, test_data, infer=False, infer_steps=3, infer_alpha=0.1, infer_subsample=1.0):\n",
      "    # test_data should be (LabeledSentence, sentiment) tuples\n",
      "    test_sentences, test_coarse_sentiments = zip(*test_data)\n",
      "    if infer:\n",
      "        if infer_subsample < 1.0:\n",
      "            sampled = [random.random()<infer_subsample for each in test_sentences]\n",
      "            test_sentences = [sentence for sentence,sample in zip(test_sentences,sampled) if sample]\n",
      "            test_coarse_sentiments = [sentiment for sentiment,sample in zip(test_coarse_sentiments,sampled) if sample]\n",
      "        test_regressors = concatenate([[model.infer_vector(sentence.words,steps=infer_steps,alpha=infer_alpha) for sentence in test_sentences] for model in model_list], axis=1)\n",
      "    else:\n",
      "        # use vectors left-over from bulk training        \n",
      "        test_sentence_ids, test_coarse_sentiments = zip(*[(sentence.labels[0],sentiment) for sentence,sentiment in zip(test_sentences,test_coarse_sentiments) if sentence.labels[0] in model_list[0].vocab])\n",
      "        #test_sentence_ids = [sentence.labels[0] for sentence in test_sentences if sentence.labels[0] in model_list[0].vocab]\n",
      "        test_regressors = concatenate([[model[id] for id in test_sentence_ids] for model in model_list], axis=1)\n",
      "    test_regressors = sm.add_constant(test_regressors)\n",
      "    \n",
      "    # predict & evaluate\n",
      "    test_predictions = predictor.predict(test_regressors)\n",
      "    errors = sum([1 for pair in zip(test_coarse_sentiments,[round(predict,0) for predict in test_predictions]) if pair[0] != pair[1]])\n",
      "    error_rate = errors / len(test_predictions)\n",
      "    return (error_rate, errors, len(test_predictions), predictor)\n",
      "\n",
      "def error_rate_for_imdb_model(model_list, infer=False, infer_steps=3, infer_alpha=0.1, infer_subsample=1.0):\n",
      "    \"\"\"Report error rate on IMDB Sentiment TEST sentences for given models/model-concatenations.\"\"\"\n",
      "    # global alldocs must be the 100k doc IMDB dataset in original order\n",
      "    # train data: just the full TRAIN sentences\n",
      "    train_sentence_ids = [sentence.labels[0] for sentence in alldocs[0:25000]]  # first 25k are train\n",
      "    train_coarse_sentiments = ([1.0]*12500)+([0.0]*12500)  # first 12.5k are positive, rest neg\n",
      "    # bulk-learned doc vectors for TRAIN sentences\n",
      "    train_inputs = concatenate([[model[id] for id in train_sentence_ids] for model in model_list], axis=1)\n",
      "    train_data = zip(train_coarse_sentiments, train_inputs)\n",
      "\n",
      "    predictor = logistic_predictor_from_data(train_data)\n",
      "    \n",
      "    test_coase_sentiments = train_coarse_sentiments  # same 12.5k pos, 12.5k neg\n",
      "    test_data = zip(alldocs[25000:50000],train_coarse_sentiments)  # start with all\n",
      "\n",
      "    return errors_from_model(model_list, predictor, test_data, infer=infer, infer_steps=infer_steps, infer_alpha=infer_alpha, infer_subsample=infer_subsample)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "best_error = defaultdict(lambda :1.0)\n",
      "\n",
      "import gensim.models.doc2vec\n",
      "gensim.models.doc2vec.FAST_VERSION"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "2"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Bulk Training"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use manual multiple-pass, alpha-reduction approach as sketched in [gensim doc2vec blog post](http://radimrehurek.com/2014/12/doc2vec-tutorial/) \u2013 with added shuffling of corpus on each pass.\n",
      "\n",
      "Note that training is occurring on *all* phrases of the dataset, which includes all TRAIN/TEST/DEV sentences and their subphrases. (The subphrases aren't marked as TRAIN/TEST/DEV or with their source sentence - for now skipping the (239K phrases * 12K sentences) substring search that'd be required to split.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#del models_by_name['dbow_100n']\n",
      "#del models_by_name['dbow_100hs']\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#models_by_name['dmc_100nhs']=[Doc2Vec(dm=1,dm_concat=1,size=100,window=5,negative=5,hs=1,min_count=1,workers=4,seed=1)]\n",
      "#models_by_name['dmc_100nhs'][0].build_vocab(alldocs)\n",
      "#models_by_name['dm_100nhs']=[Doc2Vec(dm=1,size=100,window=5,negative=5,hs=1,min_count=1,workers=4,seed=1)]\n",
      "#models_by_name['dm_100nhs'][0].build_vocab(alldocs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for model_list in models_by_name.values():\n",
      "#    if len(model_list) == 1:\n",
      "#        model_list[0].reset_weights()\n",
      "        \n",
      "#models_by_name['dmc_300n3']=models_by_name['dmc_300n15']\n",
      "#del models_by_name['dmc_300n15']\n",
      "#models_by_name['dmc_300n3'][0].negative=3\n",
      "#models_by_name['dmc_300n3'][0].reset_weights()\n",
      "#models_by_name['dmc_300n3'][0].negative\n",
      "\n",
      "# ran about 8 passes with all vectors locked, then unlocked just doc-vectors\n",
      "for model_list in models_by_name.values():\n",
      "    if len(model_list) == 1:\n",
      "        for i, word in enumerate(model_list[0].index2word):\n",
      "            if word.startswith('_*'):\n",
      "                model_list[0].syn0locks[i] = 1.0\n",
      "        #model_list[0].syn0locks.fill(0.0) # lock everything\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "models_by_name['dbow_8n5'][0].index2word[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "['strikebreakers',\n",
        " \"'mikey'\",\n",
        " '_*23014',\n",
        " 'mstgysgt',\n",
        " 'mayedas',\n",
        " '_*34309',\n",
        " 'probing',\n",
        " '_*70961',\n",
        " '_*99471',\n",
        " '_*80098']"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from random import shuffle\n",
      "import datetime\n",
      "\n",
      "alpha = 0.025 # 0.025\n",
      "passes = 40\n",
      "alpha_delta = (alpha - 0.0001) / passes\n",
      "\n",
      "assess_per = 1 # assess only once per...?\n",
      "infer_per = 10  # inference still quite slow: only do every Nth pass\n",
      "infer_steps = 3\n",
      "infer_alpha = 0.1\n",
      "infer_subsample = 0.2\n",
      "\n",
      "print(\"START \"+str(datetime.datetime.now()))\n",
      "\n",
      "for epoch in range(passes):\n",
      "    shuffle(doc_list)  # shuffling gets best results\n",
      "    \n",
      "    for name, model in models_by_name.items():\n",
      "        # train\n",
      "        duration = 'na'\n",
      "        if len(model) == 1:\n",
      "            # only train the pure models\n",
      "            model[0].alpha = alpha\n",
      "            model[0].min_alpha = alpha\n",
      "            with elapsed_timer() as elapsed:\n",
      "                model[0].train(doc_list)\n",
      "            duration = '%.1f' % elapsed()\n",
      "        # evaluate\n",
      "        if (epoch+1) % assess_per == 0:\n",
      "            eval_duration = ''\n",
      "            with elapsed_timer() as eval_elapsed:\n",
      "                (err, err_count, test_count, predictor) = error_rate_for_imdb_model(model)\n",
      "            eval_duration = '%.1f' % eval_elapsed()\n",
      "            if err < best_error[name]:\n",
      "                best_error[name] = err\n",
      "                print(\"%f : %i passes : %s %ss %ss\"%(err,epoch+1,name, duration, eval_duration))\n",
      "        if ((epoch+1) % infer_per == 0): # or epoch == 0:\n",
      "            eval_duration = ''\n",
      "            with elapsed_timer() as eval_elapsed:\n",
      "                (infer_err, err_count, test_count, predictor) = error_rate_for_imdb_model(model,infer=True,infer_steps=infer_steps,infer_alpha=infer_alpha,infer_subsample=infer_subsample)\n",
      "            eval_duration = '%.1f' % eval_elapsed()\n",
      "            if infer_err < best_error[name+'_inferred']:\n",
      "                best_error[name+'_inferred'] = infer_err\n",
      "                print(\"%f : %i passes : %s %ss %ss\"%(infer_err,epoch+1,name+'_inferred', duration, eval_duration))\n",
      "\n",
      "    print('completed pass %i at alpha %f'%(epoch+1,alpha))\n",
      "    alpha -= alpha_delta\n",
      "    \n",
      "print(\"END \"+str(datetime.datetime.now()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "START 2015-05-07 04:10:34.942160\n",
        "0.311640 : 1 passes : dmc_8n5 77.2s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.322320 : 1 passes : dm_8n5 42.7s 0.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.350960 : 1 passes : dbow_8n5 39.4s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 1 at alpha 0.025000\n",
        "0.265320 : 2 passes : dmc_8n5 69.0s 2.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.286920 : 2 passes : dm_8n5 40.7s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.288400 : 2 passes : dbow_8n5 38.6s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 2 at alpha 0.024377\n",
        "0.243480 : 3 passes : dmc_8n5 66.4s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.270640 : 3 passes : dm_8n5 38.5s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.262920 : 3 passes : dbow_8n5 34.7s 1.9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 3 at alpha 0.023755\n",
        "0.233240 : 4 passes : dmc_8n5 64.5s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.258880 : 4 passes : dm_8n5 36.1s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.242120 : 4 passes : dbow_8n5 34.3s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 4 at alpha 0.023132\n",
        "0.220840 : 5 passes : dmc_8n5 64.2s 1.9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.253520 : 5 passes : dm_8n5 36.2s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.229960 : 5 passes : dbow_8n5 34.1s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 5 at alpha 0.022510\n",
        "0.215560 : 6 passes : dmc_8n5 65.2s 0.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.248280 : 6 passes : dm_8n5 40.3s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.221480 : 6 passes : dbow_8n5 38.3s 1.9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 6 at alpha 0.021887\n",
        "0.208120 : 7 passes : dmc_8n5 80.7s 0.5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.246400 : 7 passes : dm_8n5 54.3s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.213680 : 7 passes : dbow_8n5 58.4s 0.6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 7 at alpha 0.021265\n",
        "0.204800 : 8 passes : dmc_8n5 107.5s 3.7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.243120 : 8 passes : dm_8n5 54.6s 0.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.210040 : 8 passes : dbow_8n5 51.5s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 8 at alpha 0.020642\n",
        "0.202320 : 9 passes : dmc_8n5 104.9s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.239960 : 9 passes : dm_8n5 55.2s 3.9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.206040 : 9 passes : dbow_8n5 50.8s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 9 at alpha 0.020020\n",
        "0.200960 : 10 passes : dmc_8n5 101.6s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.193869 : 10 passes : dmc_8n5_inferred 101.6s 320.5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.239398 : 10 passes : dm_8n5_inferred 52.8s 217.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.202680 : 10 passes : dbow_8n5 45.0s 0.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.193587 : 10 passes : dbow_8n5_inferred 45.0s 133.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 10 at alpha 0.019397\n",
        "0.199120 : 11 passes : dmc_8n5 101.6s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.237800 : 11 passes : dm_8n5 53.7s 2.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.200880 : 11 passes : dbow_8n5 53.9s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 11 at alpha 0.018775\n",
        "0.197760 : 12 passes : dmc_8n5 102.2s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.198000 : 12 passes : dbow_8n5 51.4s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 12 at alpha 0.018152\n",
        "0.196560 : 13 passes : dmc_8n5 95.2s 2.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.235360 : 13 passes : dm_8n5 46.8s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.195720 : 13 passes : dbow_8n5 44.6s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 13 at alpha 0.017530\n",
        "0.195600 : 14 passes : dmc_8n5 94.0s 0.6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.234080 : 14 passes : dm_8n5 58.3s 2.7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.195360 : 14 passes : dbow_8n5 50.1s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 14 at alpha 0.016907\n",
        "0.193120 : 15 passes : dbow_8n5 55.9s 2.7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 15 at alpha 0.016285\n",
        "0.194560 : 16 passes : dmc_8n5 99.1s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.191960 : 16 passes : dbow_8n5 39.4s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 16 at alpha 0.015662\n",
        "0.193200 : 17 passes : dmc_8n5 68.9s 2.0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.233720 : 17 passes : dm_8n5 36.8s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.190680 : 17 passes : dbow_8n5 34.0s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 17 at alpha 0.015040\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-15-55cfb79f3fbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0melapsed_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0melapsed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%.1f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0melapsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/scratch/Documents/dev2015/gensim_venv/src/gensim-develop/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, total_words, word_count, chunksize)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mjob_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"putting job #%i in the queue, qsize=%i\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjob_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reached the end of input; waiting to finish %i outstanding jobs\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/scratch/miniconda3/envs/gensim_cenv/lib/python3.4/queue.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(self, item, block, timeout)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/scratch/miniconda3/envs/gensim_cenv/lib/python3.4/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for model_list in models_by_name.values():\n",
      "    if len(model_list) == 1:\n",
      "        for i, word in enumerate(model_list[0].index2word):\n",
      "            if not word.startswith('_*'):\n",
      "                model_list[0].syn0locks[i] = 0.1\n",
      "models_by_name['dbow_8n5'][0].syn0locks[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "array([ 0.1,  0.1,  1. ,  0.1,  0.1,  1. ,  0.1,  1. ,  1. ,  1. ], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alpha = 0.015 # 0.025\n",
      "passes = 10\n",
      "alpha_delta = 0 # (alpha - 0.0001) / passes\n",
      "\n",
      "assess_per = 1 # assess only once per...?\n",
      "infer_per = 10  # inference still quite slow: only do every Nth pass\n",
      "infer_steps = 3\n",
      "infer_alpha = 0.1\n",
      "infer_subsample = 0.2\n",
      "\n",
      "print(\"START \"+str(datetime.datetime.now()))\n",
      "\n",
      "for epoch in range(passes):\n",
      "    shuffle(doc_list)  # shuffling gets best results\n",
      "    \n",
      "    for name, model in models_by_name.items():\n",
      "        # train\n",
      "        duration = 'na'\n",
      "        if len(model) == 1:\n",
      "            # only train the pure models\n",
      "            model[0].alpha = alpha\n",
      "            model[0].min_alpha = alpha\n",
      "            with elapsed_timer() as elapsed:\n",
      "                model[0].train(doc_list)\n",
      "            duration = '%.1f' % elapsed()\n",
      "        # evaluate\n",
      "        if (epoch+1) % assess_per == 0:\n",
      "            eval_duration = ''\n",
      "            with elapsed_timer() as eval_elapsed:\n",
      "                (err, err_count, test_count, predictor) = error_rate_for_imdb_model(model)\n",
      "            eval_duration = '%.1f' % eval_elapsed()\n",
      "            if err < best_error[name]:\n",
      "                best_error[name] = err\n",
      "                print(\"%f : %i passes : %s %ss %ss\"%(err,epoch+1,name, duration, eval_duration))\n",
      "        if ((epoch+1) % infer_per == 0): # or epoch == 0:\n",
      "            eval_duration = ''\n",
      "            with elapsed_timer() as eval_elapsed:\n",
      "                (infer_err, err_count, test_count, predictor) = error_rate_for_imdb_model(model,infer=True,infer_steps=infer_steps,infer_alpha=infer_alpha,infer_subsample=infer_subsample)\n",
      "            eval_duration = '%.1f' % eval_elapsed()\n",
      "            if infer_err < best_error[name+'_inferred']:\n",
      "                best_error[name+'_inferred'] = infer_err\n",
      "                print(\"%f : %i passes : %s %ss %ss\"%(infer_err,epoch+1,name+'_inferred', duration, eval_duration))\n",
      "\n",
      "    print('completed pass %i at alpha %f'%(epoch+1,alpha))\n",
      "    alpha -= alpha_delta\n",
      "    \n",
      "print(\"END \"+str(datetime.datetime.now()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "START 2015-05-07 05:14:05.281087\n",
        "0.188720 : 1 passes : dbow_8n5 32.9s 2.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 1 at alpha 0.015000\n",
        "0.187240 : 2 passes : dbow_8n5 33.3s 0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 2 at alpha 0.015000\n",
        "completed pass 3 at alpha 0.015000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.186640 : 4 passes : dbow_8n5 32.3s 1.8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 4 at alpha 0.015000\n",
        "completed pass 5 at alpha 0.015000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 6 at alpha 0.015000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.185400 : 7 passes : dbow_8n5 31.8s 1.9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "completed pass 7 at alpha 0.015000\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-18-3ff505fde4be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0melapsed_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0melapsed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%.1f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0melapsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/scratch/Documents/dev2015/gensim_venv/src/gensim-develop/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, total_words, word_count, chunksize)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;31m# convert input strings to Vocab objects (eliding OOV/downsampled words), and start filling the jobs queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mjob_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"putting job #%i in the queue, qsize=%i\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjob_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/scratch/Documents/dev2015/gensim_venv/src/gensim-develop/gensim/utils.py\u001b[0m in \u001b[0;36mchunkize_serial\u001b[0;34m(iterable, chunksize, as_numpy)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0mwrapped_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mwrapped_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrapped_chunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/scratch/Documents/dev2015/gensim_venv/src/gensim-develop/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36m_prepare_sentences\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# avoid calling random_sample() where prob >= 1, to speed things up a little:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             sampled = [self.vocab[word] for word in sentence.words\n\u001b[0m\u001b[1;32m    392\u001b[0m                        if word in self.vocab and (self.vocab[word].sample_probability >= 1.0 or\n\u001b[1;32m    393\u001b[0m                                                   self.vocab[word].sample_probability >= random.random_sample())]\n",
        "\u001b[0;32m/Users/scratch/Documents/dev2015/gensim_venv/src/gensim-develop/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# avoid calling random_sample() where prob >= 1, to speed things up a little:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             sampled = [self.vocab[word] for word in sentence.words\n\u001b[0;32m--> 392\u001b[0;31m                        if word in self.vocab and (self.vocab[word].sample_probability >= 1.0 or\n\u001b[0m\u001b[1;32m    393\u001b[0m                                                   self.vocab[word].sample_probability >= random.random_sample())]\n\u001b[1;32m    394\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print best error rates achieved\n",
      "errs = [(rate,name) for name, rate in best_error.items()]\n",
      "errs.sort(key=lambda pair: pair[0])\n",
      "for err in errs:\n",
      "    print(\"%f %s\"%(err[0],err[1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(models_by_name['dbow_100'][0].most_similar('_*1'), models_by_name['dm_100'][0].most_similar('_*1'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#  notable: model trained from larger IMDB dataset does better against RoTo data than the native models\n",
      "from gensim.corpora import susentcorpus\n",
      "corpus = susentcorpus.StanfordSentimentCorpus('stanfordSentimentTreebank')\n",
      "corpus.split(corpus.TEST)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_data = [ (LabeledSentence([w.lower() for w in p.text.split()],['_*'+str(p.id)]), round(p.sentiment)) for p in corpus.split(corpus.TRAIN)]\n",
      "rate,errs,total,predictor = error_rate_for_imdb_model(models_by_name['dm+dbow'])\n",
      "errors_from_model(models_by_name['dm+dbow'],predictor,test_data,infer=True,infer_alpha=0.1,infer_steps=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = models_by_name['dbow_100'][0]\n",
      "model.create_binary_tree()\n",
      "model.vocab['plot'].point"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = models_by_name['dbow_mikolov_wordless'][0]\n",
      "model.sample = 1e-5\n",
      "model.precalc_sampling()\n",
      "downsampled_words = [item for item in model.vocab.items() if item[1].sample_probability < 1.0]\n",
      "downsampled_words.sort(key=lambda item: item[1].sample_probability)\n",
      "' '.join([k for k,v in downsampled_words])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.vocab['_*91588'].count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\" \".join([word for word, lock in zip(dm_preload.index2word,dm_preload.syn0locks) if lock == 1 and not word.startswith(\"_*\")][:100])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(error_rate_for_model(models_by_name['dbow_mikolov_no_neg5'],alldocs),\n",
      " error_rate_for_model(models_by_name['dbow_mikolov_no_neg5'],alldocs,infer=True,steps=3,alpha=0.1,infer_subsample=0.1),\n",
      " error_rate_for_model(models_by_name['dbow_mikolov_no_neg5'],alldocs,infer=True,steps=40,alpha=0.05,infer_subsample=0.2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Miscellaneous"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim.models import Word2Vec\n",
      "g100b_model = Word2Vec.load_word2vec_format('/Users/scratch/Documents/dev2015/GoogleNews-vectors-negative300.bin.gz',binary=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# do the nearby words make sense?\n",
      "from IPython.display import HTML\n",
      "word = 'hot'\n",
      "unimodels = [ (name, model_list[0]) for name, model_list in models_by_name.items() if len(model_list) == 1 ]\n",
      "#unimodels += [ ('g100b', g100b_model)]\n",
      "similars_per_model = [str(model.most_similar(word,topn=20)).replace('), ','),<br>\\n') for name,model in unimodels]\n",
      "similar_table = (\"<table><tr><th>\" +\n",
      "    \"</th><th>\".join([name for name, model in unimodels]) + \n",
      "    \"</th></tr><tr><td>\" +\n",
      "    \"</td><td>\".join(similars_per_model) +\n",
      "    \"</td></tr></table>\")\n",
      "print(\"most similar words for %s\"%word)\n",
      "HTML(similar_table)\n",
      "# IMO all kind of weak compared to larger datasets; DMC/neg looked best after ~13 equal passes "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "most similar words for hot\n"
       ]
      },
      {
       "html": [
        "<table><tr><th>dmc_8n5</th><th>dm_8n5</th><th>dbow_8n5</th></tr><tr><td>[('moralistic', 0.9930219054222107),<br>\n",
        "('suicidal', 0.9897444248199463),<br>\n",
        "('unappreciative', 0.988795816898346),<br>\n",
        "('self-centred', 0.9880788326263428),<br>\n",
        "('dreamy', 0.9873833656311035),<br>\n",
        "('naive', 0.9857485890388489),<br>\n",
        "('willowy', 0.9856183528900146),<br>\n",
        "('sparkling', 0.9855660796165466),<br>\n",
        "('perverted', 0.9840306639671326),<br>\n",
        "('stoic', 0.9839687347412109),<br>\n",
        "('pushy', 0.9809291958808899),<br>\n",
        "('friendly', 0.9806541204452515),<br>\n",
        "('playful', 0.9804766774177551),<br>\n",
        "('sanctimonious', 0.9792925119400024),<br>\n",
        "('prominent', 0.9790276288986206),<br>\n",
        "('neurotic', 0.97899329662323),<br>\n",
        "('methodical', 0.9785575866699219),<br>\n",
        "('freakish', 0.9778721332550049),<br>\n",
        "('diverging', 0.9776245355606079),<br>\n",
        "('flamboyant', 0.9774649739265442)]</td><td>[('fat', 0.9829730987548828),<br>\n",
        "('embarased', 0.9704914689064026),<br>\n",
        "('computery', 0.9693061113357544),<br>\n",
        "('underage', 0.9689414501190186),<br>\n",
        "('sykes', 0.9673709273338318),<br>\n",
        "('forbin', 0.9642382264137268),<br>\n",
        "('burly', 0.9597094058990479),<br>\n",
        "(\"delon's\", 0.9574135541915894),<br>\n",
        "('thin/young/beautiful', 0.9572716355323792),<br>\n",
        "('racer', 0.9561551809310913),<br>\n",
        "('bluto', 0.9541059732437134),<br>\n",
        "(\"'fairy'\", 0.9540327191352844),<br>\n",
        "('depravities', 0.9528664350509644),<br>\n",
        "('addison', 0.9511017799377441),<br>\n",
        "('music-narrated', 0.9484331011772156),<br>\n",
        "('matango', 0.9472157955169678),<br>\n",
        "('dunes', 0.9442881941795349),<br>\n",
        "('naked', 0.9437516927719116),<br>\n",
        "('semprinni20', 0.9425346255302429),<br>\n",
        "('mazovia', 0.9414047002792358)]</td><td>[('blind-siding', 0.9675828814506531),<br>\n",
        "('caesar-was', 0.9596400260925293),<br>\n",
        "('asteroid', 0.9564988613128662),<br>\n",
        "(\"`rope'\", 0.9563028812408447),<br>\n",
        "('panzerkreuzer', 0.9553191661834717),<br>\n",
        "(\"lithgow's\", 0.9538893103599548),<br>\n",
        "('ghosts/zombies/ghouls', 0.9535247087478638),<br>\n",
        "('busiest', 0.9531139731407166),<br>\n",
        "('whorehouse', 0.9483261108398438),<br>\n",
        "('non-reappearance', 0.9443132877349854),<br>\n",
        "('else---that', 0.9438615441322327),<br>\n",
        "(\"odile's\", 0.9429396390914917),<br>\n",
        "('sub-characters', 0.9368915557861328),<br>\n",
        "('duffers', 0.9367499351501465),<br>\n",
        "('perle', 0.9361903071403503),<br>\n",
        "('five-six', 0.9354174733161926),<br>\n",
        "('trenchcoat', 0.9349865913391113),<br>\n",
        "(\"ghetto's\", 0.93492591381073),<br>\n",
        "('half-an-hour', 0.9342410564422607),<br>\n",
        "(\"girl'\", 0.9338379502296448)]</td></tr></table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "<IPython.core.display.HTML at 0x1d2113668>"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#models_by_name['dbow_8n5'][0].seeded_vector('plot'+str(305253))\n",
      "plot_index = models_by_name['dbow_8n5'][0].vocab['plot'].index\n",
      "models_by_name['dbow_8n5'][0].syn0[plot_index]\n",
      "models_by_name['dbow_8n5'][0].seeded_vector('plot'+str(1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "array([ 0.0508047 ,  0.00550329,  0.03671667, -0.03782919, -0.05103629,\n",
        "        0.00968521, -0.02264824,  0.01856799])"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "models_by_name['dbow_8n5'][0]['plot']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "array([ 0.0508047 ,  0.00550329,  0.03671667, -0.03782919, -0.05103629,\n",
        "        0.00968521, -0.02264824,  0.01856799], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "models_by_name['dbow_8n5'][0].reset_weights()\n",
      "models_by_name['dbow_8n5'][0]['plot']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "array([ 0.0508047 ,  0.00550329,  0.03671667, -0.03782919, -0.05103629,\n",
        "        0.00968521, -0.02264824,  0.01856799], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# what are nearby bulk-trained vectors for an inferred vector?\n",
      "phrase = alldocs[0]\n",
      "tokens = phrase.words\n",
      "similars_per_model = [str(model.most_similar([model.infer_vector(tokens,steps=3,alpha=0.1)])).replace('), ','),<br>\\n') for name,model in unimodels]\n",
      "print(\"most similar docs for: '%s'\" %(phrase.words))\n",
      "similar_table = (\"<table><tr><th>\" +\n",
      "    \"</th><th>\".join([name for name, model in unimodels]) + \n",
      "    \"</th></tr><tr><td>\" +\n",
      "    \"</td><td>\".join(similars_per_model) +\n",
      "    \"</td></tr></table>\")\n",
      "HTML(similar_table)\n",
      "# in DBOW, often phrase itself or subphrase... less consistent DM/DM_CONCAT"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "' '.join(alldocs[1082].words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import logging\n",
      "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
      "rootLogger = logging.getLogger()\n",
      "rootLogger.setLevel(logging.INFO)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time unimodels[1][1].accuracy('/Users/scratch/Documents/gensim/questions-words.txt')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time unimodels[1][1].accuracy('/Users/scratch/Documents/gensim/questions-words.txt')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time unimodels[2][1].accuracy('/Users/scratch/Documents/gensim/questions-words.txt')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "not_in_g100b = []\n",
      "overlap_g100b = []\n",
      "for k in dbow_model.vocab:\n",
      "    if k.startswith('PHR_'):\n",
      "        continue\n",
      "    if k not in g100b_model.vocab:\n",
      "        not_in_g100b.append(k)\n",
      "    else:\n",
      "        overlap_g100b.append(k)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(not_in_g100b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(overlap_g100b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "not_in_g100b[-100:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"G100B_words.txt\",'w') as f:\n",
      "    for k in g100b_model.vocab:\n",
      "        f.write(str(k))\n",
      "        f.write('\\n')\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "del g100b_model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}